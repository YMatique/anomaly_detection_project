# ==================== MAIN.PY CORRIGIDO ====================
"""
Interface principal do Sistema de Detec√ß√£o de Invas√µes
VERS√ÉO CORRIGIDA - SEM BUG DE MEM√ìRIA
"""
import os
import sys
import argparse
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
import cv2
import time
from collections import deque
import tensorflow as tf
from tensorflow.keras.layers import (
    Input, ConvLSTM2D, BatchNormalization, Flatten, 
    Dense, Reshape, RepeatVector
)
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
import gc

# ==================== CONFIGURA√á√ïES OTIMIZADAS ====================
class Config:
    # Par√¢metros reduzidos para evitar OOM
    FRAME_HEIGHT = 64   # Reduzido de 224 para 64
    FRAME_WIDTH = 64    # Reduzido de 224 para 64
    SEQUENCE_LENGTH = 8  # Reduzido de 16 para 8
    CHANNELS = 3
    
    # Par√¢metros de treinamento otimizados
    BATCH_SIZE = 2      # Reduzido de 4 para 2
    EPOCHS = 30         # Reduzido de 50 para 30
    LEARNING_RATE = 0.001
    VALIDATION_SPLIT = 0.2
    
    # Par√¢metros do modelo reduzidos
    CONV_LSTM_FILTERS = (8, 16, 8)  # Reduzido de (32, 64, 32)
    DROPOUT_RATE = 0.2
    
    # Limites de mem√≥ria
    MAX_SEQUENCES_PER_VIDEO = 30
    MAX_TOTAL_SEQUENCES = 100
    
    # Caminhos
    DATA_DIR = "data"
    MODEL_DIR = "models"
    RESULTS_DIR = "results"
    
    @property
    def input_shape(self):
        return (self.SEQUENCE_LENGTH, self.FRAME_HEIGHT, 
                self.FRAME_WIDTH, self.CHANNELS)

# ==================== PROCESSAMENTO DE DADOS OTIMIZADO ====================
class VideoProcessor:
    def __init__(self, config):
        self.config = config
        
    def extract_sequences_from_video(self, video_path, overlap=4):
        """Extrai sequ√™ncias de frames de um v√≠deo com controle de mem√≥ria"""
        print(f"Processando: {os.path.basename(video_path)}")
        cap = cv2.VideoCapture(video_path)
        
        if not cap.isOpened():
            print(f"  ‚ùå Erro ao abrir v√≠deo")
            return []
        
        sequences = []
        frames_buffer = []
        frame_count = 0
        
        try:
            while len(sequences) < self.config.MAX_SEQUENCES_PER_VIDEO:
                ret, frame = cap.read()
                if not ret:
                    break
                
                try:
                    processed_frame = self.preprocess_frame(frame)
                    frames_buffer.append(processed_frame)
                    frame_count += 1
                    
                    if len(frames_buffer) == self.config.SEQUENCE_LENGTH:
                        sequence = np.array(frames_buffer, dtype=np.float32)
                        sequences.append(sequence)
                        frames_buffer = frames_buffer[overlap:]
                        
                        if len(sequences) % 10 == 0:
                            print(f"  üìä {len(sequences)} sequ√™ncias...")
                            gc.collect()
                            
                except Exception as e:
                    print(f"  ‚ö†Ô∏è Erro frame {frame_count}: {e}")
                    continue
                    
        except Exception as e:
            print(f"  ‚ùå Erro geral: {e}")
        finally:
            cap.release()
            del frames_buffer
            gc.collect()
        
        print(f"  ‚úÖ Extra√≠das {len(sequences)} sequ√™ncias de {frame_count} frames")
        return sequences
    
    def preprocess_frame(self, frame):
        """Pr√©-processa um frame"""
        frame = cv2.resize(frame, (self.config.FRAME_WIDTH, self.config.FRAME_HEIGHT))
        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        frame = frame.astype(np.float32) / 255.0
        return frame
    
    def load_normal_data(self, data_dir):
        """Carrega dados normais para treinamento com controle de mem√≥ria"""
        normal_dir = os.path.join(data_dir, "normal")
        if not os.path.exists(normal_dir):
            raise ValueError(f"Diret√≥rio {normal_dir} n√£o encontrado")
        
        video_files = [f for f in os.listdir(normal_dir) 
                      if f.endswith(('.mp4', '.avi', '.mov', '.MP4', '.AVI', '.MOV'))]
        
        if not video_files:
            raise ValueError(f"Nenhum v√≠deo encontrado em {normal_dir}")
        
        # Limitar n√∫mero de v√≠deos se necess√°rio
        max_videos = min(len(video_files), 5)  # M√°ximo 5 v√≠deos
        video_files = video_files[:max_videos]
        
        print(f"üìπ Processando {len(video_files)} v√≠deos (m√°x {max_videos})")
        
        all_sequences = []
        
        for i, video_file in enumerate(video_files):
            print(f"\nüé¨ V√≠deo {i+1}/{len(video_files)}: {video_file}")
            
            if len(all_sequences) >= self.config.MAX_TOTAL_SEQUENCES:
                print("‚ö†Ô∏è Limite de sequ√™ncias atingido")
                break
            
            video_path = os.path.join(normal_dir, video_file)
            try:
                video_sequences = self.extract_sequences_from_video(video_path)
                
                if video_sequences:
                    remaining = self.config.MAX_TOTAL_SEQUENCES - len(all_sequences)
                    sequences_to_add = video_sequences[:remaining]
                    all_sequences.extend(sequences_to_add)
                    print(f"  ‚úÖ Adicionadas {len(sequences_to_add)} sequ√™ncias")
                
                del video_sequences
                gc.collect()
                
            except Exception as e:
                print(f"  ‚ùå Erro ao processar {video_file}: {e}")
                continue
        
        if not all_sequences:
            raise ValueError("Nenhuma sequ√™ncia v√°lida foi extra√≠da dos v√≠deos")
        
        print(f"\n‚úÖ Total: {len(all_sequences)} sequ√™ncias")
        
        # Converter para array NumPy
        sequences_array = np.array(all_sequences, dtype=np.float32)
        print(f"üìä Shape final: {sequences_array.shape}")
        print(f"üíæ Tamanho: {sequences_array.nbytes / 1024 / 1024:.1f} MB")
        
        del all_sequences
        gc.collect()
        
        return sequences_array

# ==================== MODELO CORRIGIDO ====================
def build_convlstm_autoencoder_fixed(input_shape, conv_lstm_filters=(8, 16, 8)):
    """
    ConvLSTM Autoencoder CORRIGIDO - SEM DENSE GIGANTE
    """
    print(f"üîß Construindo modelo para: {input_shape}")
    
    # Input layer
    input_layer = Input(shape=input_shape, name='input_sequence')
    print(f"   Input: {input_layer.shape}")
    
    # Encoder ConvLSTM
    print("   Encoder...")
    x = ConvLSTM2D(
        filters=conv_lstm_filters[0],
        kernel_size=(3, 3),
        padding='same',
        return_sequences=True,
        activation='tanh',
        name='conv_lstm_1'
    )(input_layer)
    x = BatchNormalization()(x)
    
    x = ConvLSTM2D(
        filters=conv_lstm_filters[1],
        kernel_size=(3, 3),
        padding='same',
        return_sequences=True,
        activation='tanh',
        name='conv_lstm_2'
    )(x)
    x = BatchNormalization()(x)
    
    # Bottleneck ConvLSTM
    print("   Bottleneck...")
    encoded = ConvLSTM2D(
        filters=conv_lstm_filters[2],
        kernel_size=(3, 3),
        padding='same',
        return_sequences=True,  # ‚úÖ MANTER SEQU√äNCIAS
        activation='tanh',
        name='encoded'
    )(x)
    
    # Decoder ConvLSTM - SEM DENSE GIGANTE!
    print("   Decoder...")
    x = ConvLSTM2D(
        filters=conv_lstm_filters[1],
        kernel_size=(3, 3),
        padding='same',
        return_sequences=True,
        activation='tanh',
        name='conv_lstm_decode_1'
    )(encoded)
    x = BatchNormalization()(x)
    
    x = ConvLSTM2D(
        filters=conv_lstm_filters[0],
        kernel_size=(3, 3),
        padding='same',
        return_sequences=True,
        activation='tanh',
        name='conv_lstm_decode_2'
    )(x)
    x = BatchNormalization()(x)
    
    # Camada de sa√≠da - reconstruir RGB
    print("   Sa√≠da...")
    decoded = ConvLSTM2D(
        filters=input_shape[-1],  # 3 canais RGB
        kernel_size=(3, 3),
        padding='same',
        return_sequences=True,
        activation='sigmoid',
        name='output_sequence'
    )(x)
    
    print(f"   Output: {decoded.shape}")
    
    model = Model(input_layer, decoded, name='ConvLSTM_Autoencoder_Fixed')
    print("‚úÖ Modelo constru√≠do sem Dense gigante!")
    
    return model

# ==================== DETECTOR OTIMIZADO ====================
class AnomalyDetector:
    def __init__(self, model_path, threshold=0.05):
        self.model = tf.keras.models.load_model(model_path)
        self.threshold = threshold
        self.sequence_buffer = deque(maxlen=8)  # Reduzido para 8
        self.config = Config()
        
        # Estat√≠sticas
        self.frame_count = 0
        self.anomaly_count = 0
        self.processing_times = []
    
    def preprocess_frame(self, frame):
        """Pr√©-processa frame para infer√™ncia"""
        frame = cv2.resize(frame, (self.config.FRAME_WIDTH, self.config.FRAME_HEIGHT))
        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        frame = frame.astype(np.float32) / 255.0
        return frame
    
    def detect_anomaly(self, frame):
        """Detecta anomalia em um frame"""
        start_time = time.time()
        
        # Pr√©-processar frame
        processed_frame = self.preprocess_frame(frame)
        self.sequence_buffer.append(processed_frame)
        
        # Verificar se buffer est√° cheio
        if len(self.sequence_buffer) < 8:
            return False, 0.0, 0.0
        
        # Preparar sequ√™ncia
        sequence = np.array(list(self.sequence_buffer), dtype=np.float32)
        sequence_batch = np.expand_dims(sequence, axis=0)
        
        # Predi√ß√£o
        try:
            reconstruction = self.model.predict(sequence_batch, verbose=0)
            mse_error = np.mean((sequence - reconstruction[0]) ** 2)
            
            # Limpeza de mem√≥ria
            del sequence, sequence_batch, reconstruction
            
        except Exception as e:
            print(f"Erro na predi√ß√£o: {e}")
            return False, 0.0, 0.0
        
        # Detectar anomalia
        is_anomaly = mse_error > self.threshold
        
        # Estat√≠sticas
        processing_time = time.time() - start_time
        self.processing_times.append(processing_time)
        
        if is_anomaly:
            self.anomaly_count += 1
        
        self.frame_count += 1
        
        return is_anomaly, mse_error, processing_time
    
    def get_statistics(self):
        """Retorna estat√≠sticas do detector"""
        if not self.processing_times:
            return {}
        
        return {
            'total_frames': self.frame_count,
            'anomalies_detected': self.anomaly_count,
            'anomaly_rate': self.anomaly_count / max(self.frame_count, 1),
            'avg_processing_time': np.mean(self.processing_times),
            'fps': 1.0 / np.mean(self.processing_times) if self.processing_times else 0
        }

# ==================== TREINAMENTO OTIMIZADO ====================
def train_model():
    """Fun√ß√£o de treinamento otimizada"""
    print("="*50)
    print("üè† SISTEMA DE DETEC√á√ÉO DE INVAS√ïES")
    print("üéØ Vers√£o Otimizada - Sem OOM")
    print("="*50)
    
    config = Config()
    
    # Verificar mem√≥ria dispon√≠vel
    try:
        import psutil
        memory = psutil.virtual_memory()
        print(f"üíæ RAM dispon√≠vel: {memory.available / 1024**3:.1f} GB")
        
        if memory.available < 2 * 1024**3:
            print("‚ö†Ô∏è Pouca RAM - ajustando par√¢metros...")
            config.MAX_TOTAL_SEQUENCES = 50
            config.BATCH_SIZE = 1
    except ImportError:
        print("üíæ psutil n√£o dispon√≠vel - usando configura√ß√£o padr√£o")
    
    # Criar diret√≥rios
    os.makedirs(config.MODEL_DIR, exist_ok=True)
    os.makedirs(config.RESULTS_DIR, exist_ok=True)
    
    print(f"\n‚öôÔ∏è Configura√ß√£o otimizada:")
    print(f"   Resolu√ß√£o: {config.FRAME_WIDTH}√ó{config.FRAME_HEIGHT}")
    print(f"   Sequ√™ncia: {config.SEQUENCE_LENGTH} frames")
    print(f"   Batch size: {config.BATCH_SIZE}")
    print(f"   M√°x sequ√™ncias: {config.MAX_TOTAL_SEQUENCES}")
    
    print("\nüìÅ Carregando dados...")
    processor = VideoProcessor(config)
    
    try:
        sequences = processor.load_normal_data(config.DATA_DIR)
        print(f"‚úÖ Dados carregados: {sequences.shape}")
    except ValueError as e:
        print(f"‚ùå Erro: {e}")
        print("\nüí° INSTRU√á√ïES:")
        print("1. Crie o diret√≥rio 'data/normal'")
        print("2. Adicione v√≠deos de comportamentos normais")
        print("3. Execute novamente")
        return False
    
    # Dividir dados
    train_sequences, val_sequences = train_test_split(
        sequences, test_size=config.VALIDATION_SPLIT, random_state=42
    )
    
    print(f"\nüìà Divis√£o:")
    print(f"   Treinamento: {len(train_sequences)} sequ√™ncias")
    print(f"   Valida√ß√£o: {len(val_sequences)} sequ√™ncias")
    
    # Construir modelo CORRIGIDO
    print("\nüîß Construindo modelo ConvLSTM corrigido...")
    try:
        model = build_convlstm_autoencoder_fixed(
            input_shape=config.input_shape,
            conv_lstm_filters=config.CONV_LSTM_FILTERS
        )
        
        # Compilar modelo
        model.compile(
            optimizer=Adam(learning_rate=config.LEARNING_RATE),
            loss='mse',
            metrics=['mae']
        )
        
        print("‚úÖ Modelo constru√≠do e compilado!")
        print(f"üìä Par√¢metros: {model.count_params():,}")
        
    except Exception as e:
        print(f"‚ùå Erro ao construir modelo: {e}")
        return False
    
    # Callbacks
    model_path = os.path.join(config.MODEL_DIR, "best_model_fixed.h5")
    callbacks = [
        EarlyStopping(
            monitor='val_loss',
            patience=7,
            restore_best_weights=True,
            verbose=1
        ),
        ModelCheckpoint(
            filepath=model_path,
            monitor='val_loss',
            save_best_only=True,
            verbose=1
        ),
        ReduceLROnPlateau(
            monitor='val_loss',
            factor=0.5,
            patience=3,
            min_lr=1e-7,
            verbose=1
        )
    ]
    
    # Treinamento
    print(f"\nüöÄ Iniciando treinamento...")
    try:
        history = model.fit(
            train_sequences, train_sequences,  # Autoencoder
            batch_size=config.BATCH_SIZE,
            epochs=config.EPOCHS,
            validation_data=(val_sequences, val_sequences),
            callbacks=callbacks,
            verbose=1
        )
        
        print("\nüéâ Treinamento conclu√≠do!")
        
        # Salvar gr√°ficos
        save_training_plots(history, config.RESULTS_DIR)
        
        print(f"üíæ Modelo salvo: {model_path}")
        return True
        
    except Exception as e:
        print(f"‚ùå Erro durante treinamento: {e}")
        return False
    finally:
        # Limpeza de mem√≥ria
        del train_sequences, val_sequences
        gc.collect()

def save_training_plots(history, results_dir):
    """Salva gr√°ficos do treinamento"""
    try:
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))
        
        # Loss
        ax1.plot(history.history['loss'], label='Treinamento', color='blue')
        ax1.plot(history.history['val_loss'], label='Valida√ß√£o', color='red')
        ax1.set_title('Loss do Modelo Otimizado')
        ax1.set_xlabel('√âpocas')
        ax1.set_ylabel('MSE')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # MAE
        ax2.plot(history.history['mae'], label='Treinamento', color='blue')
        ax2.plot(history.history['val_mae'], label='Valida√ß√£o', color='red')
        ax2.set_title('Mean Absolute Error')
        ax2.set_xlabel('√âpocas')
        ax2.set_ylabel('MAE')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        plot_path = os.path.join(results_dir, 'training_history_fixed.png')
        plt.savefig(plot_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"üìà Gr√°fico salvo: {plot_path}")
        
    except Exception as e:
        print(f"‚ö†Ô∏è Erro ao salvar gr√°ficos: {e}")

# ==================== DETEC√á√ÉO EM TEMPO REAL ====================
def real_time_detection(model_path="models/best_model_fixed.h5", threshold=0.05, source=0):
    """Executa detec√ß√£o em tempo real"""
    print("="*50)
    print("üè† DETECTOR DE INVAS√ïES - VERS√ÉO OTIMIZADA")
    print("="*50)
    
    # Verificar modelo
    if not os.path.exists(model_path):
        # Tentar modelo padr√£o se o otimizado n√£o existir
        fallback_path = "models/best_model.h5"
        if os.path.exists(fallback_path):
            model_path = fallback_path
            print(f"‚ö†Ô∏è Usando modelo padr√£o: {model_path}")
        else:
            print(f"‚ùå Modelo n√£o encontrado: {model_path}")
            print("üí° Execute: python main.py --mode train")
            return False
    
    # Inicializar detector
    print("ü§ñ Carregando modelo...")
    try:
        detector = AnomalyDetector(model_path, threshold)
        print("‚úÖ Modelo carregado!")
    except Exception as e:
        print(f"‚ùå Erro: {e}")
        return False
    
    # Inicializar c√¢mera
    print(f"üìπ Conectando √† fonte ({source})...")
    cap = cv2.VideoCapture(source)
    
    if not cap.isOpened():
        print("‚ùå Erro ao abrir fonte de v√≠deo")
        return False
    
    print("‚úÖ Fonte conectada!")
    print("\nüéÆ CONTROLES:")
    print("   'q' - Sair")
    print("   's' - Screenshot")
    print("   ESPA√áO - Pausar")
    
    screenshot_count = 0
    paused = False
    
    try:
        while True:
            if not paused:
                ret, frame = cap.read()
                if not ret:
                    break
                
                # Detectar anomalia
                is_anomaly, error, proc_time = detector.detect_anomaly(frame)
                
                # Visualiza√ß√£o
                display_frame = frame.copy()
                
                if is_anomaly:
                    color = (0, 0, 255)
                    status = "üö® INVAS√ÉO!"
                    thickness = 3
                else:
                    color = (0, 255, 0)
                    status = "‚úÖ NORMAL"
                    thickness = 2
                
                # Adicionar informa√ß√µes
                cv2.putText(display_frame, status, (10, 40), 
                           cv2.FONT_HERSHEY_SIMPLEX, 1.2, color, thickness)
                cv2.putText(display_frame, f"Erro: {error:.4f}", (10, 80), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)
                cv2.putText(display_frame, f"Threshold: {threshold:.4f}", (10, 120), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)
                
                if proc_time > 0:
                    fps = 1.0 / proc_time
                    cv2.putText(display_frame, f"FPS: {fps:.1f}", (10, 160), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)
                
                # Estat√≠sticas
                stats = detector.get_statistics()
                if stats:
                    cv2.putText(display_frame, f"Frames: {stats['total_frames']}", (10, 200), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 200, 200), 1)
                    cv2.putText(display_frame, f"Anomalias: {stats['anomalies_detected']}", (10, 220), 
                               cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 200, 200), 1)
            
            # Mostrar frame
            cv2.imshow('Detector Otimizado - ConvLSTM', display_frame if not paused else frame)
            
            # Controles
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q'):
                break
            elif key == ord('s'):
                os.makedirs("results/screenshots", exist_ok=True)
                timestamp = time.strftime("%Y%m%d_%H%M%S")
                screenshot_name = f"results/screenshots/fixed_{timestamp}_{screenshot_count:03d}.png"
                cv2.imwrite(screenshot_name, display_frame if not paused else frame)
                print(f"üì∏ Screenshot: {screenshot_name}")
                screenshot_count += 1
            elif key == ord(' '):
                paused = not paused
                print(f"‚è∏Ô∏è {'Pausado' if paused else 'Continuando'}")
                
    except KeyboardInterrupt:
        print("\n‚èπÔ∏è Interrompido pelo usu√°rio")
    finally:
        cap.release()
        cv2.destroyAllWindows()
        
        # Estat√≠sticas finais
        stats = detector.get_statistics()
        if stats:
            print("\nüìä ESTAT√çSTICAS:")
            print("="*30)
            for key, value in stats.items():
                if isinstance(value, float):
                    print(f"{key}: {value:.4f}")
                else:
                    print(f"{key}: {value}")
        
        return True

# ==================== FUN√á√ÉO PRINCIPAL ====================
def main():
    """Fun√ß√£o principal"""
    parser = argparse.ArgumentParser(
        description='üè† Sistema Otimizado de Detec√ß√£o de Invas√µes',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Exemplos de uso:
  python main.py --mode train                    # Treinar modelo otimizado
  python main.py --mode detect                   # Detec√ß√£o com webcam
  python main.py --mode detect --source video.mp4  # Detec√ß√£o com v√≠deo
  python main.py --mode detect --threshold 0.03     # Threshold personalizado
        """
    )
    
    parser.add_argument('--mode', choices=['train', 'detect'], 
                       required=True, help='Modo de opera√ß√£o')
    parser.add_argument('--model', default='models/best_model_fixed.h5',
                       help='Caminho do modelo')
    parser.add_argument('--threshold', type=float, default=0.05,
                       help='Threshold para detec√ß√£o')
    parser.add_argument('--source', default=0,
                       help='Fonte de v√≠deo: 0 para webcam ou caminho do arquivo')
    
    args = parser.parse_args()
    
    # Converter source para int se for n√∫mero
    try:
        args.source = int(args.source)
    except ValueError:
        pass
    
    print(f"TensorFlow: {tf.__version__}")
    print(f"NumPy: {np.__version__}")
    
    if args.mode == 'train':
        success = train_model()
        sys.exit(0 if success else 1)
    elif args.mode == 'detect':
        success = real_time_detection(args.model, args.threshold, args.source)
        sys.exit(0 if success else 1)

if __name__ == "__main__":
    main()